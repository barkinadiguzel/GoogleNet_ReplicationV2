# ğŸŒ€ InceptionV2-Replication PyTorch Implementation

This repository contains a replication of **InceptionV2**, based on the paper **â€œRethinking the Inception Architecture for Computer Visionâ€**, using PyTorch. The model is designed for **efficient image classification**, using **channel expansion at coarse grids**, **factorized convolutions**, and **auxiliary classifiers**.

- Implemented **InceptionV2** using modular Inception blocks (A, B, C, D, E) with **channel expansion at multiple coarse grids** and **factorized large kernels**.

- Architecture:  
**Stem â†’ Inception3a-b â†’ GridReduction â†’ Inception4a-e + AuxClassifier â†’ GridReduction â†’ Inception5a-b â†’ GlobalAvgPool â†’ Flatten â†’ FC**  

> **Note on channel scaling:** In the original paper, channel expansion at coarse grids is static. In our implementation, channel expansion is applied at multiple coarse grids (e.g., 17Ã—17 â†’ 2Ã—, 8Ã—8 â†’ 2Ã—) to preserve feature richness while reducing computation.

**Paper reference:** [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567) 


---

## ğŸ–¼ Overview â€“ InceptionV2 Architecture

![Overview](images/figmix.jpg)  

**Figure 4:** Stem module showing initial convolution and pooling layers.  
**Figure 5:** Inception modules with factorized convolutions and branching structure.  
**Figure 7:** Coarsest grid module with **expanded channels** for richer feature representation.  

> **Model overview:**  
> InceptionV2 increases channel depth on coarse grids to capture richer features while maintaining efficient parameter usage. Factorized convolutions reduce the number of parameters while preserving receptive fields. The auxiliary classifier acts as a regularizer, helping the network avoid overfitting and slightly improving final accuracy.


---

## ğŸ“Š Model Parameters â€“ Table 1

Refer to **Table 1** in `images/figmix.jpg` for layer-wise channel sizes, kernel factorization details, and feature map dimensions.

---

## ğŸ— Project Structure

```bash
InceptionV2/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ layers/
â”‚   â”‚   â”œâ”€â”€ conv_layer.py             # 1x1, 3x3, 5x5 factorized and asym conv layers
â”‚   â”‚   â”œâ”€â”€ inception_module.py       # Inception block (A, B, C, D, E)
â”‚   â”‚   â”œâ”€â”€ flatten_layer.py          # Flatten layer
â”‚   â”‚   â”œâ”€â”€ fc_layer.py               # Fully connected layer
â”‚   â”‚   â”œâ”€â”€ pool_layers/
â”‚   â”‚   â”‚   â”œâ”€â”€ maxpool_layer.py      # MaxPool
â”‚   â”‚   â”‚   â””â”€â”€ avgpool_layer.py      # AdaptiveAvgPool
â”‚   â”‚
â”‚   â”œâ”€â”€ blocks/
â”‚   â”‚   â””â”€â”€ auxiliary_classifier.py   # Aux classifier for intermediate supervision
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ inception_v2.py           # Full InceptionV2 model combining Stem + Modules
â”‚   â”‚
â”‚   â””â”€â”€ config.py                      # Input size, num_classes, channel scaling parameters
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg                     # Figures 4, 5, 7 and Table 1
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
